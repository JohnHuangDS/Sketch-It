{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "1. Exploring the Data\n",
    "2. Logistic Regression\n",
    "3. CNN\n",
    "4. __Building Test Functions__\n",
    "\n",
    "In this section, I build function in order to create the Sketch It Game. Most of the development was completed using a text editor (Atom) and saved as a py file because openCV, the library that allows me to access the connected webcam, does not work in jupyter notebook. It will cause the kernel to crash. In order to run the game, run the file demo_game.py found in the demo folder. To run on your laptop webcam, change the source cv2.VideoCapture(1) to cv2.VideoCapture(0) where applicable in test_functions.py and demo_game.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_cnn_model \n",
    "load_cnn_model takes two inputs, model_name and model_weight_name, and returns a loaded CNN model and a list of the categories based on what the model was trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cnn_model(model_name, model_weight_name):\n",
    "    json_file = open(model_name)\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(model_weight_name)\n",
    "    loaded_model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                      optimizer = 'Adam',\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "    #get path names\n",
    "    path = r'/Users/john/Desktop/Demo_Day/Data/npy'\n",
    "    file_names = sorted(glob.glob(path +'/*.npy'))\n",
    "    file_names \n",
    "    \n",
    "    #Get the Names of the classes\n",
    "    sketch_list = []\n",
    "    for path in file_names:\n",
    "        name = (path[56:path.find('.')])\n",
    "        sketch_list.append(name)\n",
    "    sketch_list\n",
    "\n",
    "\n",
    "    return(loaded_model,sketch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x1a4be2abe0>\n",
      "['angel', 'sword', 'wine_glass', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "#testing the function\n",
    "model,sketch_list = load_model('CNN_model.json','CNN_model.h5')\n",
    "print(model)\n",
    "print(sketch_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_background \n",
    "get_background takes three inputs (set_width, set_font, font_y_pad) and returns a background_processed.  When the function is called, the webcam is activated and each image from the webcam is stored in the frame variable.  When the computer key 'y' is pressed, it takes the last image the webcam has stored and processes it. The processing includes turning the BGR image into grayscale, then removing small noise by applying Gaussian Blur. Set_width, set_font, font_y_pad are inputs that affect the shape of the frame and the text that appear on the display window. It is necccessary to scale the display window based on whichever monitor is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(set_width,set_font,font_y_pad):\n",
    "    #initiate webcam\n",
    "    cam = cv2.VideoCapture(1)\n",
    "    \n",
    "    background= None\n",
    "    run = True\n",
    "    \n",
    "    while run:\n",
    "        ret, frame = cam.read()\n",
    "        #resize frame based on set_width\n",
    "        frame2 = imutils.resize(frame, width = set_width)\n",
    "        \n",
    "        cv2.putText(frame2, 'Calibrating Background',(10,font_y_pad),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, set_font, (0, 0, 0), 2)\n",
    "\n",
    "        cv2.putText(frame2, 'Press (y) to Continue',(10,frame2.shape[0]-font_y_pad),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, set_font, (0, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"CAN YOU DRAW\",frame2)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        print(key)\n",
    "        if key == ord(\"y\"):\n",
    "            run = False\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "    #change to grayscale and apply GaussianBlur to remove small noise.\n",
    "    background = frame\n",
    "    background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "    background_gray_blur = cv2.GaussianBlur(background_gray, (5,5),0)\n",
    "    background_proccessed = background_gray_blur\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows\n",
    "    return(background_proccessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frame_preprocessing\n",
    "frame_preprocessing takes 5 inputs. frame_capture is image from the webcam that is to be processed.  x, y, w, h, are the values of a crop box around the object inside the image.  The values of x, y, w, h are found in the function get_level which will be described further down. frame_preprocessing takes an image, converts it to grayscale, and then crops the image while adding a padding.  Then, it thresholds the values at 100. This is neccessary to help when downsizing from the input frame_capture, to a 28x28 sized array which is neccesary for the prediction model.  During resizing, a BICUBIC sampling method is used.  Multiple samplying methods were tested and I found BICUBIC to give the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_preprocessing(frame_capture,x,y,w,h):\n",
    "\n",
    "    #convert to image for grascaling and crop based on crop box co-ordinates\n",
    "    pil_image = Image.fromarray(frame_capture)\n",
    "    pil_image = pil_image.convert('L')\n",
    "    \n",
    "    #if the image is taller than it is wide, adds extra padding to the width\n",
    "    if h>w:\n",
    "        pil_crop = pil_image.crop((x-50-((h-w)/2),y-50,x+w+50+((h-w)/2),y+h+50))\n",
    "        \n",
    "    #if the image is wider than it is tall, adds extra padding to the height\n",
    "    if h<w:\n",
    "        pil_crop = pil_image.crop((x-50,y-50-((w-h)/2),x+w+50,y+h+50+((w-h)/2)))\n",
    "        \n",
    "    #convert to array for thresholding(cv2.threshold can does the same thing)\n",
    "    frame_array = np.array(pil_crop)\n",
    "    frame_array = np.where(frame_array <= 100,0,frame_array)\n",
    "    frame_array = np.where(frame_array > 100, 255, frame_array)\n",
    "\n",
    "    #turn back into an image, then resize image with BICUBIC sampling and turn into an array\n",
    "    resized_image = Image.fromarray(frame_array)\n",
    "    test_array = np.array(resized_image.resize((28,28), Image.BICUBIC))\n",
    "\n",
    "    #returns an array\n",
    "    return(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_reshape_predict\n",
    "model_reshape_predict reutrns the prediction_label, as well as the softmax output from the cnn_model. It's required inputs are the image to be tested, the model to be used, and a list of the possible categories to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_reshape_predict(image, model, y_unique):\n",
    "    #Define the img rows and cols\n",
    "    img_rows = 28\n",
    "    img_cols = 28\n",
    "\n",
    "    #Reshape the image\n",
    "    test= image.reshape(1, img_rows, img_cols, 1)\n",
    "\n",
    "    #Predict based on model\n",
    "    prediction = model.predict(test)\n",
    "\n",
    "    #Create the labels off of y_unique\n",
    "    my_encoder = LabelEncoder()\n",
    "    my_encoder.fit(y_unique)\n",
    "\n",
    "    #Change prediction to label\n",
    "    pred_label = my_encoder.inverse_transform([np.argmax(prediction)])[0]\n",
    "\n",
    "    return (pred_label,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_level\n",
    "get_level creates different levels for the sketch it game.  \n",
    "level_name (string) is the a name of the object to be drawn. \n",
    "correct_answer (string) is text to be displayed when the model guesses the right answer. \n",
    "background_processed (array of integers) is the processed background photo from the function get_background. \n",
    "model and sketch_list is the same input from the function load_cnn_model. \n",
    "next_level(int) keeps track of which level will come next.  \n",
    "set_width (int) determines the width of the display window\n",
    "\n",
    "If the correct answer was guessed, the function will return the input next_level which allows the user to move onto the next level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level(level_name, correct_answer, background_processed, model, sketch_list,next_level,set_width):\n",
    "    cv2.destroyAllWindows\n",
    "    cam = cv2.VideoCapture(1)\n",
    "    \n",
    "    #initiate variables\n",
    "    guess_array = np.array([])\n",
    "    correct = level_name\n",
    "    answer = 0\n",
    "    result = 0\n",
    "    set_font = int(set_width/400)\n",
    "    font_color = (0,0,0)\n",
    "    font_y_pad = int(set_width/10)\n",
    "    \n",
    "    #initiate camera\n",
    "    start = True\n",
    "    while start == True:\n",
    "        ret, frame = cam.read()\n",
    "        \n",
    "        #display window text shows \"Undetected\"\n",
    "        text_detection = \"Undetected\"\n",
    "\n",
    "        #Process webcam image\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray_blur = cv2.GaussianBlur(gray, (5,5),0)\n",
    "        \n",
    "        #Find the difference between the gray_blur image and the background_processed image, threshold and dilate it.\n",
    "        frameDelta = cv2.absdiff(background_processed,gray_blur)\n",
    "        #this function can be used in the earlier frame preprocessing function\n",
    "        thresh = cv2.threshold(frameDelta, 50, 255, cv2.THRESH_BINARY)[1]\n",
    "        #dilation thickens the contours in the image\n",
    "        dilate = cv2.dilate(thresh, None, iterations = 2)\n",
    "\n",
    "        #Find and grab contours. cnts is an array of arrays.\n",
    "        cnts = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        \n",
    "        if answer == 0:\n",
    "            text_guess = 'Hmmmm'\n",
    "        \n",
    "        sketch_x = None\n",
    "        sketch_y = None\n",
    "        sketch_w = None\n",
    "        sketch_h = None\n",
    "        \n",
    "        #loop through the contours\n",
    "        for c in cnts:\n",
    "            #ignore really small contours\n",
    "            if cv2.contourArea(c) <set_width*set_width/250:\n",
    "                continue\n",
    "                \n",
    "            #create and draw a bounding rectangle\n",
    "            (x,y,w,h) = cv2.boundingRect(c)\n",
    "            c_area = w*h\n",
    "            #another filter to drop out small contours (this is redundant now that I see it)\n",
    "            \n",
    "            if c_area > 4000:\n",
    "                sketch_x = x\n",
    "                sketch_y = y\n",
    "                sketch_w = w\n",
    "                sketch_h = h\n",
    "        #if there are contours that meet the requirement, return a guess of what it is\n",
    "        \n",
    "        try:\n",
    "            #draws a contour onto the display window\n",
    "            cv2.rectangle(frame, (sketch_x-20,y-20),(sketch_x+sketch_w+20, sketch_y+sketch_h+20), (0,255,0),2)\n",
    "            \n",
    "            #change display window text to 'Detected'\n",
    "            text_detection = \"Detected\"\n",
    "\n",
    "            #Call our test functions from above to return a guess of the image\n",
    "            processed_frame = frame_preprocessing(dilate, sketch_x, sketch_y, sketch_w, sketch_h)\n",
    "            guess, confidence = model_reshape_predict(processed_frame, model, sketch_list)\n",
    "            guess_array = np.append(guess_array, guess)\n",
    "            print(guess)\n",
    "\n",
    "            #check to see if the last 40 items in guess.  This is useful because it shows that the model \n",
    "            #is consistently guessing the right image, as opposed to a lucky guess.\n",
    "            final_guess = np.unique(guess_array[-40:])\n",
    "            print(final_guess)\n",
    "            \n",
    "            #if the guess is corrext, the display window will display a message\n",
    "            if final_guess == correct:\n",
    "                if next_level != 5:\n",
    "                    text_guess = correct_answer + \" Press (n) to continue\"\n",
    "                else:\n",
    "                    text_guess = correct_answer\n",
    "                result = next_level\n",
    "                answer = 1\n",
    "\n",
    "        #if no contours have been detected, pass\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #Places Texts onto display window\n",
    "        cv2.putText(frame, 'Lets see you draw a {}'.format(level_name),(10,font_y_pad),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, int(set_font*1.5), (0, 0, 0), 2)\n",
    "\n",
    "        cv2.putText(frame, 'Sketch: {}'.format(text_detection),(10,2*font_y_pad),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, set_font, (0, 0, 0), 2)\n",
    "\n",
    "\n",
    "        cv2.putText(frame, \"{}\".format(text_guess), (10, frame.shape[0]-font_y_pad),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, set_font, (0, 0, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "        frame = imutils.resize(frame, width = set_width)\n",
    "        #show display window\n",
    "        cv2.imshow(\"CAN YOU DRAW\",frame)\n",
    "        \n",
    "        #Optional/for development --> shows the image that is being fed into the model\n",
    "        try:\n",
    "            cv2.imshow(\"Frame_processing\", processed_frame)\n",
    "        except:\n",
    "            pass\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        print(key)\n",
    "        if key == ord(\"n\"):\n",
    "            start = False\n",
    "        if key == ord(\"q\"):\n",
    "            result = 0\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sketch It, a machine learning drawing game\n",
    "This is the code to run the Sketch It. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMO GAME\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import model_from_json\n",
    "import test_functions\n",
    "\n",
    "\n",
    "#determine window resize(1920x1080, 1280x720, 640,480)\n",
    "set_width = 1080\n",
    "set_font = int(set_width/400)\n",
    "font_color = (0,0,0)\n",
    "font_y_pad = int(set_width/10)\n",
    "\n",
    "#Calibrate Background\n",
    "background_processed = test_functions.get_background(set_width, set_font, font_y_pad)\n",
    "print(background_processed)\n",
    "print(background_processed.shape)\n",
    "\n",
    "#Load Test models\n",
    "model,sketch_list = test_functions.load_cnn_model('CNN_model_demo_day2.json','CNN_model_demo_day2.h5')\n",
    "print(sketch_list)\n",
    "\n",
    "what = cv2.VideoCapture(1)\n",
    "run = True\n",
    "while run:\n",
    "    #Load Level\n",
    "\n",
    "    result = 0\n",
    "    ret, frame = what.read()\n",
    "    frame = imutils.resize(frame, width = set_width)\n",
    "\n",
    "    cv2.putText(frame, \"Welcome to 'Can you draw?''\",(10,font_y_pad),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, set_font, font_color, 2)\n",
    "\n",
    "    cv2.putText(frame, \"Press (s) to start\",(10,frame.shape[0]-2*font_y_pad),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, set_font, font_color, 2)\n",
    "\n",
    "    cv2.putText(frame, \"Press (r) to recalibrate\",(10,frame.shape[0]-font_y_pad),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, set_font, font_color, 2)\n",
    "\n",
    "    cv2.imshow(\"CAN YOU DRAW\",frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    # Loads different levels, notice that the next level can only be accessed if the drawing was guessed correctly.\n",
    "    if key == ord(\"r\"):\n",
    "        background_processed = test_functions.get_background(set_width, set_font, font_y_pad)\n",
    "\n",
    "    if key == ord(\"s\"):\n",
    "        cv2.destroyAllWindows\n",
    "        result = test_functions.get_level('wine glass','Thats a wine glass alright.',background_processed, model, sketch_list,2, set_width)\n",
    "\n",
    "    if result == 2:\n",
    "        result = test_functions.get_level('sword','ZING ZING, thats a sword!',background_processed, model, sketch_list,3,set_width)\n",
    "\n",
    "    if result == 3:\n",
    "        result = test_functions.get_level('angel','What a beautiful Angel',background_processed, model, sketch_list,4,set_width)\n",
    "\n",
    "    if result == 4:\n",
    "        result = test_functions.get_level('yoga','Nice! Thats its, thanks for playing!',background_processed, model, sketch_list,5,set_width)\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
